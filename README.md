
<h2>Interpretable Machine Learning Papers</h2>


<ul>

                             

 <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(1).pdf" style="text-decoration:none;">How to Explain Individual Classification Decisions</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(2).pdf" style="text-decoration:none;">To Explain or to Predict?</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(3).pdf" style="text-decoration:none;">Peeking Inside the Black Box: Visualizing Statistical Learning with Plots of Individual Conditional Expectation</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(4).pdf" style="text-decoration:none;">Visualizing and Understanding Convolutional Networks</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(5).pdf" style="text-decoration:none;">Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(6).pdf" style="text-decoration:none;">Understanding Neural Networks Through Deep Visualization</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(7).pdf" style="text-decoration:none;">Interpretable classifiers using rules and Bayesian analysis: Building a better stroke prediction model</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(8).pdf" style="text-decoration:none;"> "Why Should I Trust You?" Explaining the Predictions of Any Classifier </a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(9).pdf" style="text-decoration:none;">Generating Visual Explanations</a></li>
  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(10).pdf" style="text-decoration:none;">The Mythos of Model Interpretability </a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(11).pdf" style="text-decoration:none;">Rationalizing Neural Predictions</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(12).pdf" style="text-decoration:none;">A Model Explanation System: Latest Updates and Extensions</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(13).pdf" style="text-decoration:none;">RETAIN: An Interpretable Predictive Model for Healthcare using Reverse Time Attention Mechanism</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(14).pdf" style="text-decoration:none;">Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization</a></li>
                              
<li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(15).pdf" style="text-decoration:none;">Gradients of Counterfactuals</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(16).pdf" style="text-decoration:none;">Towards A Rigorous Science of Interpretable Machine Learning</a></li>

  <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(17).pdf" style="text-decoration:none;">Axiomatic Attribution for Deep Networks</a></li>   
  
<li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(18).pdf" style="text-decoration:none;">Understanding Black-box Predictions via Influence Functions</a></li> 

  
<li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(19).pdf" style="text-decoration:none;">High-Resolution Breast Cancer Screening with Multi-View Deep Convolutional Neural Networks</a></li> 

<li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(20).pdf" style="text-decoration:none;">Learning Important Features Through Propagating Activation Differences</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(21).pdf" style="text-decoration:none;">A Unified Approach to Interpreting Model Predictions</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(22).pdf" style="text-decoration:none;">SVCCA: Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics and Interpretability</a></li> 
 <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(23).pdf" style="text-decoration:none;">The (Un) reliability of saliency methods</a></li> 
 

   <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(24).pdf" style="text-decoration:none;">Learning Explanatory Rules from Noisy Data</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(25).pdf" style="text-decoration:none;">Relief-Based Feature Selection: Introduction and Review</a></li>                              
 <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(26).pdf" style="text-decoration:none;">Benchmarking Relief-Based Feature Selection Methods for Bioinformatics Data Mining</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(27).pdf" style="text-decoration:none;">Extracting Automata from Recurrent Neural Networks Using Queries and Counter examples</a></li>
   
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(28).pdf" style="text-decoration:none;">Distilling a Neural Network Into a Soft Decision Tree</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(29).pdf" style="text-decoration:none;">Visual Explanation by Interpretation: Improving Visual Feedback Capabilities of Deep Neural Networks </a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(30).pdf" style="text-decoration:none;">All Models are Wrong, but Many are Useful: Learning a Variable's Importance by Studying an Entire Class of Prediction Models Simultaneously</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(31).pdf" style="text-decoration:none;">TSViz: Demystification of Deep Learning Models for Time-Series Analysis</a></li> 
    <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(32).pdf" style="text-decoration:none;">Learning to Explain: An Information-Theoretic Perspective on Model Interpretation</a></li> 

   <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(33).pdf" style="text-decoration:none;">Explanations of model predictions with live and breakDown packages</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(34).pdf" style="text-decoration:none;">Visualizing the Feature Importance for Black Box Models</a></li> 
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(35).pdf" style="text-decoration:none;">Computer Vision and Image Understanding</a></li> 

  <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(36).pdf" style="text-decoration:none;">Explaining Explanations: An Overview of Interpretability of Machine Learning</a></li> 
 
<li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(37).pdf" style="text-decoration:none;">Hierarchical interpretations for neural network predictions</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(38).pdf" style="text-decoration:none;">A Benchmark for Interpretability Methods in Deep Neural Networks</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(39).pdf" style="text-decoration:none;">iNNvestigate neural networks!</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(40).pdf" style="text-decoration:none;">YASENN: Explaining Neural Networks via Partitioning Activation Sequences</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(41).pdf" style="text-decoration:none;">Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(42).pdf" style="text-decoration:none;">Interpretable machine learning: definitions, methods, and applications</a></li>
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(43).pdf" style="text-decoration:none;">Attention is not Explanation</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(44).pdf" style="text-decoration:none;">Quantifying Model Complexity via Functional Decomposition for Better Post-Hoc Interpretability</a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(45).pdf" style="text-decoration:none;">Please Stop Permuting Features: An Explanation and Alternatives</a></li>  
   
<li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(46).pdf" style="text-decoration:none;">Please Stop Permuting Features: An Explanation and Alternatives</a></li> 
                             
<li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(47).pdf" style="text-decoration:none;">Attention Interpretability Across NLP Tasks</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(48).pdf" style="text-decoration:none;">GRACE: Generating Concise and Informative Contrastive Sample to Explain Neural Network Model's Prediction</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(49).pdf" style="text-decoration:none;">Transparent Classification with Multilayer Logical Perceptrons and Random Binarization</a></li>
                              
<li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(50).pdf" style="text-decoration:none;">Model-agnostic Feature Importance and Effects with Dependent Features &minus; A Conditional Subgroup Approach</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(51).pdf" style="text-decoration:none;">Pitfalls to Avoid when Interpreting Machine Learning Models</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(52).pdf" style="text-decoration:none;">Interpreting Deep Glucose Predictive Models for Diabetic People Using RETAIN</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(53).pdf" style="text-decoration:none;">MeLIME: Meaningful Local Explanation for Machine Learning Models</a></li>
 
<li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(54).pdf" style="text-decoration:none;">Captum: A unified and generic model interpretability library for PyTorch </a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(55).pdf" style="text-decoration:none;">Anchors: High-Precision Model-Agnostic Explanations</a></li>
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(56).pdf" style="text-decoration:none;">Detecting Bias in Black-Box Models Using Transparent Model Distillation </a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(57).pdf" style="text-decoration:none;">An Introduction to Machine Learning Interpretability</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(58).pdf" style="text-decoration:none;">Conditional Likelihood Maximisation: A Unifying Framework for Information Theoretic Feature Selection</a></li>
    <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(59).pdf" style="text-decoration:none;">Package 'DALEX'</a></li>
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(60).pdf" style="text-decoration:none;">Rationalizing Neural Predictions </a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(61).pdf" style="text-decoration:none;">A short fscaret package introduction with examples</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(62).pdf" style="text-decoration:none;">An Introduction to Variable and Feature Selection</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(63).pdf" style="text-decoration:none;">Boruta for those in a hurry</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(64).pdf" style="text-decoration:none;">Visualizing statistical models: Removing the blindfold</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(65).pdf" style="text-decoration:none;">Consistent Feature Selection for Pattern Recognition in Polynomial Time</a></li> 

   <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(66).pdf" style="text-decoration:none;">Result Analysis of the NIPS 2003 Feature Selection Challenge</a></li> 
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(67).pdf" style="text-decoration:none;">A Unified Approach to Interpreting Model Predictions</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(68).pdf" style="text-decoration:none;">Feature Selection Via Joint Likelihood</a></li> 
 
  
   <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(69).pdf" style="text-decoration:none;">Structure mining and knowledge extraction from random forest with applications to The Cancer Genome Atlas project</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(70).pdf" style="text-decoration:none;">pdp: An R Package for Constructing Partial Dependence Plots</a></li> 
  
 
 <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(71).pdf" style="text-decoration:none;">ggfortify: Unified Interface to Visualize Statistical Results of Popular R Packages</a></li>
 
 <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(72).pdf" style="text-decoration:none;">A Model Explanation System</a></li> 
 
 
 <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(73).pdf" style="text-decoration:none;">Comprehensible Classification Models – a position paper</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(74).pdf" style="text-decoration:none;">Wald Lecture II:
Looking Inside The Black Box</a></li>
    <li><a target="_blank" href="https://github.com/manjunath5496/Interpretable-Machine-Learning-Papers/blob/master/imb(75).pdf" style="text-decoration:none;">Introduction: Mind Over Data</a></li>                        
</ul>

